{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "960d1489",
   "metadata": {},
   "source": [
    "## LLM Agent — Notebook Simples\n",
    "\n",
    "Este notebook demonstra o funcionamento básico de um **LLM Agent** utilizando a biblioteca `transformers`.\n",
    "\n",
    "O agente carrega o modelo `google/gemma-2b-it` e gera uma resposta baseada em um prompt fornecido pelo usuário.\n",
    "\n",
    "Este notebook faz parte da **Atividade #11** da disciplina de Inteligência Artificial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "MODEL_NAME = \"google/gemma-2b-it\"\n",
    "\n",
    "print(\"Carregando o modelo (pode demorar dependendo da máquina)...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=\"float32\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=150,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "print(\"Modelo carregado com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1639d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(prompt):\n",
    "    out = generator(prompt)[0][\"generated_text\"]\n",
    "    return out\n",
    "\n",
    "# Exemplo (comentado para evitar execução automática)\n",
    "# agent(\"Explique o que é um LLM Agent.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
